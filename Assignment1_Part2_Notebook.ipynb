{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "425ee227",
   "metadata": {},
   "source": [
    "# EE214 â€” Assignment 1 (Part 2)\n",
    "\n",
    "Comparative Study of Polynomial vs Gaussian Basis Functions on the Concrete Compressive Strength Dataset\n",
    "\n",
    "_This notebook was generated to run end-to-end. It includes fallbacks so it will not raise errors if the dataset is missing._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4cbff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Setup: imports and reproducibility\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "import urllib.request\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "RANDOM_SEED = 0\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "print(\"Python version:\", os.sys.version)\n",
    "print(\"Working directory:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd501b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Attempt to load the dataset from local files or download it.\n",
    "data = None\n",
    "local_xls = 'Concrete_Data.xls'\n",
    "local_csv = 'Concrete_Data.csv'\n",
    "uci_xls_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/concrete/compressive/Concrete_Data.xls'\n",
    "uci_csv_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/concrete/compressive/Concrete_Data.csv'\n",
    "\n",
    "def try_load():\n",
    "    global data\n",
    "    # Try local xls\n",
    "    if os.path.exists(local_xls):\n",
    "        print(\"Loading local file:\", local_xls)\n",
    "        try:\n",
    "            data = pd.read_excel(local_xls)\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(\"Failed to read local xls:\", e)\n",
    "    # Try local csv\n",
    "    if os.path.exists(local_csv):\n",
    "        print(\"Loading local file:\", local_csv)\n",
    "        try:\n",
    "            data = pd.read_csv(local_csv, header=None)\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(\"Failed to read local csv:\", e)\n",
    "    # Try downloading (may fail in offline environments)\n",
    "    try:\n",
    "        print(\"Trying to download from UCI (xls)...\")\n",
    "        urllib.request.urlretrieve(uci_xls_url, local_xls)\n",
    "        data = pd.read_excel(local_xls)\n",
    "        print(\"Downloaded and loaded\", local_xls)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(\"Could not download xls:\", e)\n",
    "    try:\n",
    "        print(\"Trying to download from UCI (csv)...\")\n",
    "        urllib.request.urlretrieve(uci_csv_url, local_csv)\n",
    "        data = pd.read_csv(local_csv, header=None)\n",
    "        print(\"Downloaded and loaded\", local_csv)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(\"Could not download csv:\", e)\n",
    "    return False\n",
    "\n",
    "loaded = try_load()\n",
    "if not loaded:\n",
    "    print(\"\\nWARNING: Concrete dataset not found or download failed. Creating a synthetic dataset with same shape so notebook runs end-to-end.\\n\")\n",
    "    # According to UCI: dataset has 8 features + 1 target, 1030 samples.\n",
    "    n_samples = 1030\n",
    "    n_features = 8\n",
    "    X_synth = np.random.rand(n_samples, n_features) * 10\n",
    "    # Create a synthetic target with some nonlinearity\n",
    "    y_synth = (3.5*X_synth[:,0] - 1.2*X_synth[:,1]**2 + 2.2*np.sin(X_synth[:,2]) + np.random.randn(n_samples)*2.5)\n",
    "    data = pd.DataFrame(np.column_stack((X_synth, y_synth)))\n",
    "    # Name columns similar to the real dataset\n",
    "    col_names = ['Cement','BlastFurnaceSlag','FlyAsh','Water','Superplasticizer','CoarseAggregate','FineAggregate','Age','Concrete_compressive_strength']\n",
    "    data.columns = col_names\n",
    "else:\n",
    "    # If loaded from UCI excel, ensure columns are named consistently (they vary)\n",
    "    if isinstance(data, pd.DataFrame) and data.shape[1] == 9:\n",
    "        # If header row already present, try to standardize\n",
    "        cols = data.columns.tolist()\n",
    "        if 'Concrete compressive strength(MPa , megapascals) ' in cols:\n",
    "            data = data.rename(columns={c: c.strip() for c in cols})\n",
    "            data.columns = [c.replace('\\n',' ').strip() for c in data.columns]\n",
    "            # rename last column to a concise name\n",
    "            data = data.rename(columns={data.columns[-1]: 'Concrete_compressive_strength'})\n",
    "        else:\n",
    "            # Give concise names if header is missing\n",
    "            col_names = ['Cement','BlastFurnaceSlag','FlyAsh','Water','Superplasticizer','CoarseAggregate','FineAggregate','Age','Concrete_compressive_strength']\n",
    "            data.columns = col_names\n",
    "print(\"Data shape:\", data.shape)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6485ee8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preprocess: features, target, standardize, split\n",
    "feature_cols = data.columns[:-1].tolist()\n",
    "target_col = data.columns[-1]\n",
    "X = data[feature_cols].values.astype(float)\n",
    "y = data[target_col].values.astype(float)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=RANDOM_SEED)\n",
    "print(\"Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4ba5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Polynomial Regression experiments\n",
    "poly_degrees = [1, 3, 5, 7]\n",
    "poly_train_errors = []\n",
    "poly_test_errors = []\n",
    "\n",
    "for deg in poly_degrees:\n",
    "    poly = PolynomialFeatures(degree=deg, include_bias=True)\n",
    "    X_train_poly = poly.fit_transform(X_train)\n",
    "    X_test_poly = poly.transform(X_test)\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_poly, y_train)\n",
    "    y_train_pred = model.predict(X_train_poly)\n",
    "    y_test_pred = model.predict(X_test_poly)\n",
    "    train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "    test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "    poly_train_errors.append(train_mse)\n",
    "    poly_test_errors.append(test_mse)\n",
    "    print(f\"Degree {deg}: train MSE={train_mse:.4f}, test MSE={test_mse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f768da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Gaussian basis regression (use only the first feature as in skeleton)\n",
    "def create_gaussian_design_matrix(x, n_bases, sigma=1.0):\n",
    "    # x is (n_samples,)\n",
    "    n_samples = x.shape[0]\n",
    "    X_design = np.ones((n_samples, n_bases + 1))  # bias + n_bases\n",
    "    for j in range(1, n_bases+1):\n",
    "        mu = float(j)  # centers mu_j = j\n",
    "        X_design[:, j] = np.exp(-0.5 * ((x - mu) / sigma)**2)\n",
    "    return X_design\n",
    "\n",
    "# Extract first original (standardized) feature\n",
    "x_train_feature = X_train[:, 0]\n",
    "x_test_feature = X_test[:, 0]\n",
    "\n",
    "gaussian_ns = [5, 7, 10, 15]\n",
    "gauss_train_errors = []\n",
    "gauss_test_errors = []\n",
    "\n",
    "for n in gaussian_ns:\n",
    "    X_train_gauss = create_gaussian_design_matrix(x_train_feature, n, sigma=1.0)\n",
    "    X_test_gauss = create_gaussian_design_matrix(x_test_feature, n, sigma=1.0)\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_gauss, y_train)\n",
    "    y_train_pred = model.predict(X_train_gauss)\n",
    "    y_test_pred = model.predict(X_test_gauss)\n",
    "    train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "    test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "    gauss_train_errors.append(train_mse)\n",
    "    gauss_test_errors.append(test_mse)\n",
    "    print(f\"Gaussian bases {n}: train MSE={train_mse:.4f}, test MSE={test_mse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48157b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot comparison\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(poly_degrees, poly_test_errors, 'ro-', label='Polynomial Test MSE')\n",
    "plt.plot(gaussian_ns, gauss_test_errors, 'bo-', label='Gaussian Test MSE')\n",
    "plt.xlabel('Model Complexity (Degree or # Gaussian Bases)')\n",
    "plt.ylabel('Test Mean Squared Error')\n",
    "plt.title('Polynomial vs Gaussian Basis: Test MSE Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Also show training curves\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(poly_degrees, poly_train_errors, 'r--o', label='Polynomial Train MSE')\n",
    "plt.plot(gaussian_ns, gauss_train_errors, 'b--o', label='Gaussian Train MSE')\n",
    "plt.xlabel('Model Complexity (Degree or # Gaussian Bases)')\n",
    "plt.ylabel('Train Mean Squared Error')\n",
    "plt.title('Polynomial vs Gaussian Basis: Train MSE Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bae1084",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save numeric results to a CSV for easy inspection\n",
    "results = pd.DataFrame({\n",
    "    'poly_degree': poly_degrees,\n",
    "    'poly_train_mse': poly_train_errors,\n",
    "    'poly_test_mse': poly_test_errors\n",
    "})\n",
    "results_gauss = pd.DataFrame({\n",
    "    'gauss_n': gaussian_ns,\n",
    "    'gauss_train_mse': gauss_train_errors,\n",
    "    'gauss_test_mse': gauss_test_errors\n",
    "})\n",
    "results.to_csv('/mnt/data/poly_results.csv', index=False)\n",
    "results_gauss.to_csv('/mnt/data/gauss_results.csv', index=False)\n",
    "print('Saved results to /mnt/data/poly_results.csv and /mnt/data/gauss_results.csv')\n",
    "\n",
    "\n",
    "# Save summary figures\n",
    "figpath1 = '/mnt/data/test_mse_comparison.png'\n",
    "figpath2 = '/mnt/data/train_mse_comparison.png'\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(poly_degrees, poly_test_errors, 'ro-', label='Polynomial Test MSE')\n",
    "plt.plot(gaussian_ns, gauss_test_errors, 'bo-', label='Gaussian Test MSE')\n",
    "plt.xlabel('Model Complexity (Degree or # Gaussian Bases)')\n",
    "plt.ylabel('Test Mean Squared Error')\n",
    "plt.title('Polynomial vs Gaussian Basis: Test MSE Comparison')\n",
    "plt.legend(); plt.grid(True)\n",
    "plt.savefig(figpath1)\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(poly_degrees, poly_train_errors, 'r--o', label='Polynomial Train MSE')\n",
    "plt.plot(gaussian_ns, gauss_train_errors, 'b--o', label='Gaussian Train MSE')\n",
    "plt.xlabel('Model Complexity (Degree or # Gaussian Bases)')\n",
    "plt.ylabel('Train Mean Squared Error')\n",
    "plt.title('Polynomial vs Gaussian Basis: Train MSE Comparison')\n",
    "plt.legend(); plt.grid(True)\n",
    "plt.savefig(figpath2)\n",
    "plt.close()\n",
    "print(f'Saved figures to {figpath1} and {figpath2}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cde8ef3",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "The notebook saves results and figures into `/mnt/data/`. After running it locally (or in this environment), you can download the CSVs, PNGs, and the notebook itself."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
